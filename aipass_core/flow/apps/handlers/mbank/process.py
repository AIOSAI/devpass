#!/home/aipass/.venv/bin/python3

# ===================AIPASS====================
# META DATA HEADER
# Name: process.py - Memory Bank Processing Handler
# Date: 2025-11-25
# Version: 1.3.0
# Category: flow/handlers/mbank
#
# CHANGELOG:
#   - v1.3.0 (2025-11-25): Restructured config - separated TRL mapping to flow_mbank_registry.json
#                          Updated get_ai_model() to use custom api_config.json
#   - v1.2.0 (2025-11-25): Added auto-cleanup for -TEMP files in MEMORY_BANK after processing
#   - v1.1.0 (2025-11-22): Improved JSON parsing - more robust to AI responses with extra content
#   - v1.0.0 (2025-11-21): Extracted from archive_temp/flow_mbank.py
#
# CODE STANDARDS:
#   - 3-tier compliant: NO Prax imports, NO logging
#   - Raises exceptions for errors (module logs them)
# =============================================

"""
Memory Bank Processing Handler

Pure handler for converting closed PLAN files to TRL-compliant memory bank entries.
Follows Seed architecture: NO Prax imports, NO logging calls.

Key Functions:
- process_closed_plans() - Main entry point for processing
- extract_plan_content() - Extract meaningful content from PLAN
- generate_trl_tags() - AI-powered TRL classification
- create_memory_entry() - Convert to memory_bank format
- archive_plan() - Move to archive folder
- is_template_content() - Template detection
- verify_and_heal_orphaned_plans() - Orphan healing logic
"""

import sys
from pathlib import Path

AIPASS_ROOT = Path.home() / "aipass_core"
sys.path.insert(0, str(AIPASS_ROOT))

# Standard imports
import json
import re
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any

# Import OpenRouter API via module layer (cross-branch access)
from api.apps.modules.openrouter_client import get_response

# =============================================
# CONSTANTS
# =============================================

FLOW_ROOT = AIPASS_ROOT / "flow"
FLOW_JSON_DIR = FLOW_ROOT / "flow_json"
MEMORY_BANK_PATH = Path.home() / "MEMORY_BANK" / "plans"
PROCESSED_PLANS_DIR = AIPASS_ROOT / "backup_system" / "processed_plans"
REGISTRY_FILE = FLOW_JSON_DIR / "flow_registry.json"
CONFIG_FILE = FLOW_JSON_DIR / "flow_mbank_config.json"
TRL_REGISTRY_FILE = FLOW_JSON_DIR / "flow_mbank_registry.json"
API_CONFIG_FILE = FLOW_ROOT / "apps" / "handlers" / "json_templates" / "custom" / "api_config.json"

# =============================================
# CONFIGURATION
# =============================================

def load_config() -> Dict[str, Any]:
    """Load flow_mbank configuration"""
    default_config = {
        "module_name": "flow_mbank",
        "version": "1.0.0",
        "config": {
            "enabled": True,
            "archive_processed": True
        }
    }

    if not CONFIG_FILE.exists():
        CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, indent=2, ensure_ascii=False)
        return default_config

    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        raise Exception(f"Failed to load config: {e}")

def load_trl_registry() -> Dict[str, Any]:
    """Load TRL mapping registry"""
    default_registry = {
        "module_name": "flow_mbank",
        "description": "TRL (Type-Category-Action) classification registry for memory bank processing",
        "version": "1.0.0",
        "trl_mapping": {
            "types": {
                "SEED": "Seed AI System",
                "NEXUS": "Nexus AI System",
                "SKILL": "Skills Modules",
                "PRAX": "Prax Infrastructure",
                "FLOW": "Flow Workflow System",
                "BACKUP": "Backup System",
                "DRONE": "Drone Commands",
                "HELP": "Help System",
                "MCP": "MCP Servers",
                "TOOLS": "Tools & Scripts"
            },
            "categories": {
                "API": "API & External Services",
                "MEM": "Memory & Storage",
                "DB": "Database & Data",
                "UI": "User Interface",
                "CFG": "Configuration",
                "DOC": "Documentation",
                "TEST": "Testing & QA",
                "SEC": "Security",
                "NET": "Networking",
                "FILE": "File Operations",
                "LOG": "Logging & Monitoring",
                "DEV": "Development"
            },
            "actions": {
                "IMP": "Implementation",
                "FIX": "Bug Fixes",
                "UPD": "Updates & Improvements",
                "NEW": "New Features",
                "REF": "Refactoring",
                "DOC": "Documentation",
                "TEST": "Testing",
                "CFG": "Configuration",
                "MIGR": "Migration",
                "OPT": "Optimization"
            }
        },
        "excluded_paths": [
            "admin", "archive", "backups", "tests", "trash", "__pycache__",
            ".git", ".venv", "venv", "node_modules", "mcp_servers"
        ]
    }

    if not TRL_REGISTRY_FILE.exists():
        TRL_REGISTRY_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(TRL_REGISTRY_FILE, 'w', encoding='utf-8') as f:
            json.dump(default_registry, f, indent=2, ensure_ascii=False)
        return default_registry

    try:
        with open(TRL_REGISTRY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        raise Exception(f"Failed to load TRL registry: {e}")

def get_ai_model() -> Optional[str]:
    """Get AI model from custom API config"""
    try:
        if API_CONFIG_FILE.exists():
            with open(API_CONFIG_FILE, 'r', encoding='utf-8') as f:
                api_config = json.load(f)
                return api_config.get("api_settings", {}).get("model")

        return None

    except Exception:
        return None

# =============================================
# REGISTRY OPERATIONS
# =============================================

def load_flow_registry() -> Dict[str, Any]:
    """Load the flow registry"""
    if not REGISTRY_FILE.exists():
        raise Exception(f"Flow registry not found at {REGISTRY_FILE}")

    try:
        with open(REGISTRY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        raise Exception(f"Failed to load flow registry: {e}")

def save_flow_registry(registry: Dict[str, Any]):
    """Save the flow registry"""
    try:
        registry["last_updated"] = datetime.now(timezone.utc).isoformat()
        with open(REGISTRY_FILE, 'w', encoding='utf-8') as f:
            json.dump(registry, f, indent=2, ensure_ascii=False)
    except Exception as e:
        raise Exception(f"Failed to save flow registry: {e}")

def get_closed_plans() -> List[Dict[str, Any]]:
    """Get closed PLANs from flow registry

    AUTO-HEAL: Before getting closed plans, verify and heal any orphaned plans

    Returns:
        List of dicts with keys: number, path, info
    """
    # AUTO-HEAL LAYER: Fix orphaned plans before processing new ones
    heal_result = verify_and_heal_orphaned_plans()

    registry = load_flow_registry()
    closed_plans = []

    for plan_num, plan_info in registry.get("plans", {}).items():
        if plan_info.get("status") == "closed" and plan_info.get("processed") != True:
            file_path = Path(plan_info.get("file_path", ""))
            if file_path.exists():
                closed_plans.append({
                    "number": plan_num,
                    "path": file_path,
                    "info": plan_info
                })

    return closed_plans

# =============================================
# TEMPLATE DETECTION
# =============================================

def is_template_content(content: str) -> bool:
    """Check if plan content is still unedited template (v2.1)

    Args:
        content: Plan file content

    Returns:
        True if 4+ template markers present (essentially untouched)
    """
    template_indicators = [
        "[What do you want to achieve? Be specific about the end state.]",
        "[Break down into 3-5 concrete goals. What must be accomplished?]",
        "[How will you tackle this? Research first? Agents for broad analysis? Direct work?]",
        "[Document each significant action with outcome]",
        "[Working notes, discoveries, important context]",
        "[What defines complete for this specific PLAN?]"
    ]

    markers_found = sum(1 for indicator in template_indicators if indicator in content)
    return markers_found >= 4

# =============================================
# CONTENT ANALYSIS
# =============================================

def analyze_plan_content(plan_path: Path) -> Dict[str, str]:
    """Use OpenRouter to analyze plan content and determine TRL tags

    Args:
        plan_path: Path to PLAN file

    Returns:
        Dict with keys: type, category, action, summary

    Raises:
        Exception: If API call fails or response is invalid
    """
    trl_registry = load_trl_registry()

    # Read plan content
    with open(plan_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Prepare analysis prompt
    try:
        relative_path = str(plan_path.relative_to(AIPASS_ROOT))
        folder_context = str(plan_path.parent.relative_to(AIPASS_ROOT))
    except ValueError:
        # Plan is outside AIPASS_ROOT
        relative_path = str(plan_path)
        folder_context = str(plan_path.parent)

    # Generate dynamic prompt from TRL mapping registry
    trl_mapping = trl_registry["trl_mapping"]

    types_desc = "\n".join([f"{k}: {v}" for k, v in trl_mapping["types"].items()])
    categories_desc = "\n".join([f"{k}: {v}" for k, v in trl_mapping["categories"].items()])
    actions_desc = "\n".join([f"{k}: {v}" for k, v in trl_mapping["actions"].items()])

    type_codes = "|".join(trl_mapping["types"].keys())
    category_codes = "|".join(trl_mapping["categories"].keys())
    action_codes = "|".join(trl_mapping["actions"].keys())

    prompt = f"""Analyze this completed plan file:

Content: {content}
Folder: {folder_context}
File: {plan_path.name}

Determine the primary classification using these options:

TYPE options:
{types_desc}

CATEGORY options:
{categories_desc}

ACTION options:
{actions_desc}

Return ONLY a JSON object:
{{
  "type": "{type_codes}",
  "category": "{category_codes}",
  "action": "{action_codes}",
  "summary": "brief description"
}}"""

    # Get AI model from openrouter's API config
    ai_model = get_ai_model()

    # Call unified API system
    response = get_response(prompt, model=ai_model, caller="flow_mbank")

    if response:
        try:
            # Extract content from response dict
            response_str = response.get('content', '').strip()

            # Check if response is wrapped in markdown code blocks
            if response_str.startswith("```json"):
                start = response_str.find("```json") + 7
                end = response_str.rfind("```")
                if end > start:
                    response_str = response_str[start:end].strip()
            elif response_str.startswith("```"):
                start = response_str.find("```") + 3
                end = response_str.rfind("```")
                if end > start:
                    response_str = response_str[start:end].strip()

            # Try parsing JSON - be more robust to extra content
            try:
                analysis = json.loads(response_str)
            except json.JSONDecodeError as e:
                # If parsing fails, try to extract just the JSON object
                # Look for the first { and last }
                first_brace = response_str.find('{')
                last_brace = response_str.rfind('}')

                if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                    json_only = response_str[first_brace:last_brace + 1]
                    try:
                        analysis = json.loads(json_only)
                    except json.JSONDecodeError:
                        # Still failed - raise original error
                        raise Exception(f"API returned invalid JSON: {e}")
                else:
                    raise Exception(f"API returned invalid JSON: {e}")

            # Validate required fields exist
            required_fields = ['type', 'category', 'action', 'summary']
            for field in required_fields:
                if field not in analysis:
                    raise Exception(f"API response missing required field: {field}")

            return analysis
        except json.JSONDecodeError as e:
            raise Exception(f"API returned invalid JSON: {e}")
    else:
        raise Exception("No response from OpenRouter API - check API key and connection")

# =============================================
# MEMORY BANK CREATION
# =============================================

def create_memory_entry(plan_path: Path, analysis: Dict[str, str]) -> Optional[Path]:
    """Create memory bank entry from analyzed plan

    Args:
        plan_path: Path to source PLAN file
        analysis: Dict with type, category, action, summary

    Returns:
        Path to created memory file, or None on failure
    """
    try:
        # Read plan content
        with open(plan_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # Check if content is still template
        is_template = is_template_content(content)

        # Get folder context
        try:
            relative_path = plan_path.relative_to(AIPASS_ROOT)
            folder_context = str(relative_path.parent).replace("\\", "-").replace("/", "-")
        except ValueError:
            # Plan is outside AIPASS_ROOT
            relative_path = plan_path
            folder_context = str(plan_path.parent).replace("\\", "-").replace("/", "-")

        if folder_context == "." or folder_context == "":
            folder_context = "root"

        # Create filename: PATH-TYPE-CATEGORY-ACTION-FPLAN-XXXX-YYYYMMDD.md
        today = datetime.now().strftime("%Y%m%d")
        plan_num = plan_path.stem.replace("FPLAN-", "")
        template_suffix = "-TEMP" if is_template else ""
        filename = f"{folder_context}-{analysis['type']}-{analysis['category']}-{analysis['action']}-FPLAN-{plan_num}{template_suffix}-{today}.md"

        # Sanitize filename
        filename = re.sub(r'[<>:"|?*]', '-', filename)
        filename = re.sub(r'-+', '-', filename)

        memory_file = MEMORY_BANK_PATH / filename

        # Ensure memory_bank directory exists
        memory_file.parent.mkdir(parents=True, exist_ok=True)

        # Duplicate check - prevent same plan processed twice
        if memory_file.exists():
            # Memory entry already exists for this plan - skip writing
            return None

        # Create memory entry content
        memory_content = f"""# {analysis['summary']}

**Source**: {relative_path}
**TRL Tags**: {analysis['type']}-{analysis['category']}-{analysis['action']}
**Created**: {datetime.now().strftime('%Y-%m-%d')}
**Location**: {relative_path.parent}

## Summary
{analysis['summary']}

## Original Content
{content}
"""

        # Write memory entry
        with open(memory_file, 'w', encoding='utf-8') as f:
            f.write(memory_content)

        return memory_file

    except Exception as e:
        raise Exception(f"Failed to create memory entry: {e}")

# =============================================
# PLAN ARCHIVAL
# =============================================

def archive_plan(plan_path: Path) -> bool:
    """Move processed plan file to backup_system/processed_plans/

    VERIFICATION: Returns True ONLY if file successfully moved AND verified

    Args:
        plan_path: Path to PLAN file to archive

    Returns:
        True if successfully archived and verified, False otherwise
    """
    try:
        # Create processed_plans directory if it doesn't exist
        PROCESSED_PLANS_DIR.mkdir(parents=True, exist_ok=True)

        # Move plan to processed_plans directory
        destination = PROCESSED_PLANS_DIR / plan_path.name

        # Handle duplicate names by adding timestamp
        if destination.exists():
            timestamp = datetime.now().strftime("%H%M%S")
            stem = destination.stem
            suffix = destination.suffix
            destination = PROCESSED_PLANS_DIR / f"{stem}_{timestamp}{suffix}"

        # Store source path for verification
        source_path = Path(plan_path)

        # Attempt move
        plan_path.rename(destination)

        # VERIFICATION LAYER: Confirm move actually happened
        if not destination.exists():
            return False

        if source_path.exists():
            return False

        return True

    except Exception:
        return False

# =============================================
# TEMP FILE CLEANUP
# =============================================

def cleanup_temp_files() -> Dict[str, Any]:
    """Remove old -TEMP files from MEMORY_BANK (empty template plans)

    These files are created when empty template plans are closed and processed.
    They have no value and should be auto-cleaned.

    Returns:
        Dict with keys:
            - files_found: int
            - files_deleted: int
            - failed_deletes: int
            - details: list of file operations
    """
    files_found = 0
    files_deleted = 0
    failed_deletes = 0
    details = []

    try:
        # Scan MEMORY_BANK/plans/ for files with -TEMP in name
        if MEMORY_BANK_PATH.exists():
            for temp_file in MEMORY_BANK_PATH.glob("*-TEMP-*.md"):
                files_found += 1

                try:
                    # Delete the TEMP file
                    temp_file.unlink()

                    # Verify deletion
                    if not temp_file.exists():
                        files_deleted += 1
                        details.append({
                            "file": temp_file.name,
                            "status": "deleted"
                        })
                    else:
                        failed_deletes += 1
                        details.append({
                            "file": temp_file.name,
                            "status": "delete_failed",
                            "error": "File still exists after deletion"
                        })

                except Exception as e:
                    failed_deletes += 1
                    details.append({
                        "file": temp_file.name,
                        "status": "delete_failed",
                        "error": str(e)
                    })

    except Exception as e:
        # Failed to scan directory
        return {
            "files_found": 0,
            "files_deleted": 0,
            "failed_deletes": 0,
            "details": [],
            "scan_error": str(e)
        }

    return {
        "files_found": files_found,
        "files_deleted": files_deleted,
        "failed_deletes": failed_deletes,
        "details": details
    }

# =============================================
# ORPHAN HEALING
# =============================================

def verify_and_heal_orphaned_plans() -> Dict[str, Any]:
    """Cross-check registry vs filesystem and auto-heal orphaned plans

    Detects plans where registry says processed=true but file still at original location.
    Attempts to move orphaned files to processed_plans/ directory.

    Returns:
        Dict with keys:
            - orphans_found: int
            - successfully_healed: int
            - failed_to_heal: int
            - orphans: list of plan details
    """
    registry = load_flow_registry()

    orphans_found = 0
    successfully_healed = 0
    failed_to_heal = 0
    orphan_details = []

    for plan_num, plan_info in registry.get("plans", {}).items():
        # Only check plans marked as processed
        if plan_info.get("processed") == True and plan_info.get("cleanup_completed") == True:
            original_path = Path(plan_info.get("file_path", ""))

            # VERIFICATION: Does file still exist at original location?
            if original_path.exists():
                # ORPHAN DETECTED
                orphans_found += 1

                # Attempt auto-heal by moving file now
                try:
                    PROCESSED_PLANS_DIR.mkdir(parents=True, exist_ok=True)
                    destination = PROCESSED_PLANS_DIR / original_path.name

                    # Handle duplicates
                    if destination.exists():
                        timestamp = datetime.now().strftime("%H%M%S")
                        stem = destination.stem
                        suffix = destination.suffix
                        destination = PROCESSED_PLANS_DIR / f"{stem}_{timestamp}{suffix}"

                    # Attempt move
                    original_path.rename(destination)

                    # Verify move
                    if destination.exists() and not original_path.exists():
                        successfully_healed += 1
                        orphan_details.append({
                            "plan": f"FPLAN-{plan_num}",
                            "status": "healed",
                            "original_path": str(original_path),
                            "destination": str(destination)
                        })
                    else:
                        failed_to_heal += 1
                        orphan_details.append({
                            "plan": f"FPLAN-{plan_num}",
                            "status": "heal_failed",
                            "error": "Verification failed after rename",
                            "path": str(original_path)
                        })

                except Exception as e:
                    failed_to_heal += 1
                    orphan_details.append({
                        "plan": f"FPLAN-{plan_num}",
                        "status": "heal_failed",
                        "error": str(e),
                        "path": str(original_path)
                    })

    return {
        "orphans_found": orphans_found,
        "successfully_healed": successfully_healed,
        "failed_to_heal": failed_to_heal,
        "orphans": orphan_details
    }

# =============================================
# MAIN PROCESSING
# =============================================

def process_closed_plans() -> Dict[str, Any]:
    """Main function to process all closed plans

    Two-phase processing:
        Phase 1: Create memory entry (always attempted)
        Phase 2: Archive plan file (only if phase 1 succeeds)

    AUTO-HEAL: Cleans up old -TEMP files from MEMORY_BANK after processing

    Returns:
        Dict with keys:
            - success: bool
            - processed: int (successfully processed)
            - errors: int (failed)
            - results: list of per-plan results
            - error: str (if success=False)
            - cleanup: dict (TEMP file cleanup results)
    """
    try:
        # Get closed plans from registry (includes auto-heal)
        closed_plans = get_closed_plans()

        if not closed_plans:
            # No closed plans to process, but still run cleanup
            cleanup_result = cleanup_temp_files()
            return {
                "success": True,
                "processed": 0,
                "errors": 0,
                "results": [],
                "cleanup": cleanup_result
            }

        processed_count = 0
        error_count = 0
        results = []

        # Process each closed plan
        for plan in closed_plans:
            try:
                plan_path = plan["path"]
                plan_num = plan["number"]

                # Generate correlation ID for tracking
                correlation_id = f"FPLAN-{plan_num}-{datetime.now().strftime('%H%M%S')}"

                # Phase 1: Analyze content
                analysis = analyze_plan_content(plan_path)

                # Phase 2: Create memory entry
                memory_file = create_memory_entry(plan_path, analysis)

                if memory_file:
                    # Update registry - memory created
                    registry = load_flow_registry()
                    if plan_num in registry.get("plans", {}):
                        registry["plans"][plan_num]["memory_created"] = True
                        registry["plans"][plan_num]["memory_created_date"] = datetime.now(timezone.utc).isoformat()
                        registry["plans"][plan_num]["memory_file"] = str(memory_file)
                        save_flow_registry(registry)

                    # Phase 3: Archive plan to backup
                    cleanup_success = archive_plan(plan_path)

                    # Update registry with final status
                    registry = load_flow_registry()
                    if plan_num in registry.get("plans", {}):
                        registry["plans"][plan_num]["cleanup_completed"] = cleanup_success
                        registry["plans"][plan_num]["cleanup_date"] = datetime.now(timezone.utc).isoformat()

                        # Only mark as fully processed if BOTH phases succeeded
                        if cleanup_success:
                            registry["plans"][plan_num]["processed"] = True
                            registry["plans"][plan_num]["processed_date"] = datetime.now(timezone.utc).isoformat()

                        save_flow_registry(registry)

                    if cleanup_success:
                        # FULL SUCCESS
                        processed_count += 1
                        results.append({
                            "plan": f"FPLAN-{plan_num}",
                            "memory_file": str(memory_file),
                            "status": "fully_processed",
                            "correlation_id": correlation_id
                        })
                    else:
                        # PARTIAL SUCCESS
                        error_count += 1
                        results.append({
                            "plan": f"FPLAN-{plan_num}",
                            "memory_file": str(memory_file),
                            "status": "memory_created_cleanup_failed",
                            "error": "Memory bank entry created but failed to move plan to backup folder",
                            "correlation_id": correlation_id
                        })
                else:
                    error_count += 1
                    results.append({
                        "plan": f"FPLAN-{plan_num}",
                        "status": "error",
                        "error": "Failed to create memory entry",
                        "correlation_id": correlation_id
                    })

            except Exception as e:
                error_count += 1
                plan_num = plan.get('number', 'unknown')
                results.append({
                    "plan": f"FPLAN-{plan_num}",
                    "status": "error",
                    "error": str(e)
                })

        # AUTO-HEAL: Clean up old -TEMP files from MEMORY_BANK
        cleanup_result = cleanup_temp_files()

        return {
            "success": True,
            "processed": processed_count,
            "errors": error_count,
            "results": results,
            "cleanup": cleanup_result
        }

    except Exception as e:
        return {
            "success": False,
            "processed": 0,
            "errors": 0,
            "results": [],
            "error": str(e)
        }
